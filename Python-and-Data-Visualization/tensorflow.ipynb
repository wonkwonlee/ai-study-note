{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "automotive-pillow",
   "metadata": {},
   "source": [
    "# 텐서플로 기초\n",
    "\n",
    "> 인공지능의 겨울(AI Winter) 이라 불리는 시기가 두 차례 있었는데 그 중 첫 번째는 퍼셉트론의 한계를 지적한 책 **퍼셉트론**의 발간이 영향을 미쳤다.\n",
    "> \n",
    "> AND, OR, XOR 연산\n",
    "\n",
    "## 난수 Random Number\n",
    "* 신경망의 초깃값을 지정해주는 것을 **초기화(Initialization)** 이라 한다.\n",
    "* 현재 가장 많이 쓰이는 방법은 **Xavier 초기화(Xavier Initialization)**, **He 초기화(He Initialization)** 인데, 이 방법들은 랜덤하지만 어느 정도 규칙성이 있는 범위 내에서 난수를 지정한다.\n",
    "\n",
    "### 균일 분포 Unifrom distribution\n",
    "* 균일 분포란 최솟값과 최댓값 사이의 모든 수가 나올 확률이 동일한 분포\n",
    "* tf.random.uniform() 메서드 사용\n",
    "* 첫번째 인자는 결괏값의 shape, 두번째 인자는 최솟값, 세번째 인자는 최대값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "revised-album",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로 버전 확인\n",
    "import tensorflow as tf \n",
    "print(tf.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sustained-updating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.09460342 0.43960333]\n",
      " [0.9377763  0.6561382 ]\n",
      " [0.88867474 0.8846135 ]\n",
      " [0.5330832  0.3680451 ]], shape=(4, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "rand = tf.random.uniform([4,2],0,1)\n",
    "print(rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-bradley",
   "metadata": {},
   "source": [
    "### 정규 분포 Normal Distribution\n",
    "* 정규 분포는 가운데가 높고 양극단으로 갈수록 낮아지는 분포\n",
    "* tf.random.normal() 메서드 사용\n",
    "* 두번째 인자는 정규 분포의 평균, 세번째 인자는 정규 분포의 표준 편차\n",
    "    + 평균이 0이고 표준 편차가 1일 때 표준 정규 분포라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ordered-uncle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-0.40757585 -0.3489127   0.35641307  1.140465  ], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# mean = 0, std = 1\n",
    "rand = tf.random.normal([4],0,1)\n",
    "print(rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-paradise",
   "metadata": {},
   "source": [
    "## 뉴런\n",
    "* 입력 ➡️ 뉴런 ➡️ 출력\n",
    "* 입력 x ➡️ 가중치 w ➡️ 활성화함수 f ➡️ 출력 y\n",
    "* 뉴런에서 학습할 때 변하는 것은 가중치로 처음에는 초기화를 통해 랜덤한 값을 넣고 학습 과정에서 점차 일정한 값으로 수렴하게 된다.\n",
    "* 학습이 잘 된다는 것은 좋은 가중치를 얻어서 원하는 출력에 점점 가까운 값을 얻는 것을 말한다.\n",
    "* 활성화 함수는 시그모이드, ReLU 등이 쓰인다.\n",
    "    + 신경망 초창기에는 시그모이드가 주로 쓰였으니 은닉층이 다수 사용되며 ReLU가 더 많이 쓰인다.\n",
    "* 딥러닝에서 오류를 역전파(Backpropagate) 할 때 시그모이드 함수가 값이 점점 작아지는 문제로 인해 [ReLU 함수](https://www.cs.toronto.edu/~fritz/absps/reluICML.pdf)가 대안으로 제시되었다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dedicated-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation function\n",
    "import math\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hired-slovakia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5803337141450682\n"
     ]
    }
   ],
   "source": [
    "x = 1    # 입력값\n",
    "y = 0    # 출력값\n",
    "w = tf.random.normal([1],0,1)  # 초기 가중치\n",
    "\n",
    "output = sigmoid(x * w)        # 예측값  \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-details",
   "metadata": {},
   "source": [
    "### 경사 하강법 Gradient Descent\n",
    "* 실제 출력값(Output)과 기대 출력(y)의 차이를 에러(Error)라고 한다.\n",
    "* 경사 하강법은 w에 입력과 학습률(a)과 에러를 곱해주는 방법으로 *w = w + x * a * error* 라고 나타낸다.\n",
    "    + 학습률(Learning rate)는 w를 업데이트하는 정도로 큰 값으로 설정하면 학습 속도가 빠르지만 과도한 학습으로 적정 수치를 벗어날 우려가 있고 너무 작은 값은 학습 속도가 너무 느려질 수 있다.\n",
    "* 경사 하강법의 경사는 손실 곡선의 기울기를 의미한다.\n",
    "* 경사 하강법은 손실 곡선을 미분한 다음 그 값을 이용하여 가중치가 손실이 가장 낮아지는 지점에 도달하도록 반복적으로 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "original-reason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복 횟수 99 : , 에러값 : -0.10786565018391682, 결과값 : 0.10786565018391682\n",
      "반복 횟수 199 : , 에러값 : -0.053899421926197406, 결과값 : 0.053899421926197406\n",
      "반복 횟수 299 : , 에러값 : -0.035538856495399444, 결과값 : 0.035538856495399444\n",
      "반복 횟수 399 : , 에러값 : -0.026422023054466868, 결과값 : 0.026422023054466868\n",
      "반복 횟수 499 : , 에러값 : -0.020998091264506177, 결과값 : 0.020998091264506177\n",
      "반복 횟수 599 : , 에러값 : -0.01740896972097045, 결과값 : 0.01740896972097045\n",
      "반복 횟수 699 : , 에러값 : -0.01486133118912339, 결과값 : 0.01486133118912339\n",
      "반복 횟수 799 : , 에러값 : -0.012960610596220995, 결과값 : 0.012960610596220995\n",
      "반복 횟수 899 : , 에러값 : -0.01148888141704749, 결과값 : 0.01148888141704749\n",
      "반복 횟수 999 : , 에러값 : -0.010315955200393467, 결과값 : 0.010315955200393467\n"
     ]
    }
   ],
   "source": [
    "# Using gradient descent to calculate output\n",
    "\n",
    "# learning rate = 0.1\n",
    "a = 0.1\n",
    "# epoch = 1000\n",
    "for i in range(1000): \n",
    "    output = sigmoid(x * w) \n",
    "    error = y - output\n",
    "    # Training/Update\n",
    "    w = w + x * a * error\n",
    "\n",
    "    # Print only 100th result (ex i=99, 199, 299, ..., 999)\n",
    "    if i % 100 == 99:\n",
    "        print('반복 횟수 {0} : , 에러값 : {1}, 결과값 : {2}'.format(i, error, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "manual-finger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복 횟수 99 : , 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 199 : , 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 299 : , 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 399 : , 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 499 : , 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 599 : , 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 699 : , 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 799 : , 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 899 : , 에러값 : 0.5, 결과값 : 0.5\n",
      "반복 횟수 999 : , 에러값 : 0.5, 결과값 : 0.5\n"
     ]
    }
   ],
   "source": [
    "# 입력이 0이고 출력이 1\n",
    "\n",
    "x = 0\n",
    "y = 1\n",
    "#w = tf.random.normal([1], 0,1) \n",
    "#w = tf.random.uniform([1], 0,1)\n",
    "\n",
    "a = 0.1\n",
    "for i in range(1000): \n",
    "    output = sigmoid(x * w) \n",
    "    error = y - output\n",
    "    w = w + x * a * error\n",
    "    \n",
    "    if i % 100 == 99:\n",
    "        print('반복 횟수 {0} : , 에러값 : {1}, 결과값 : {2}'.format(i,error, output))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-insert",
   "metadata": {},
   "source": [
    "> error값도 결과값도 0.5에서 변하지 않는다. 왜냐하면 입력으로 넣은 수가 0이기 때문에 w가 갱신되지 않는다.\n",
    "\n",
    "\n",
    "### 편향 Bias\n",
    "* 편향은 입력으로는 늘 한쪽으로 치우친 고정된 값(b = 1)을 받아서 입력으로 0을 받았을 때 뉴런이 아무것도 배우지 못하는 상황을 방지한다.\n",
    "* 편향 역시 w처럼 난수로 초기화되서 뉴런에 더해져서 출력을 계산하게 된다.\n",
    "* 편향이 더해진 뉴런의 출력 계산식은 *Y = f(X * w + 1 * b)* 라고 나타낸다.\n",
    "\n",
    "![b](https://user-images.githubusercontent.com/28593767/111951384-f3c93500-8b26-11eb-977f-6d60e3d2d39b.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exciting-machine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복 횟수 99 : , 에러값 : 0.09448796264598214, 결과값 : 0.9055120373540179\n",
      "반복 횟수 199 : , 에러값 : 0.05016521840287913, 결과값 : 0.9498347815971209\n",
      "반복 횟수 299 : , 에러값 : 0.03384851830265623, 결과값 : 0.9661514816973438\n",
      "반복 횟수 399 : , 에러값 : 0.025468313766778605, 결과값 : 0.9745316862332214\n",
      "반복 횟수 499 : , 에러값 : 0.020388210650287508, 결과값 : 0.9796117893497125\n",
      "반복 횟수 599 : , 에러값 : 0.01698628911914557, 결과값 : 0.9830137108808544\n",
      "반복 횟수 699 : , 에러값 : 0.014551502627808577, 결과값 : 0.9854484973721914\n",
      "반복 횟수 799 : , 에러값 : 0.012723906150726938, 결과값 : 0.9872760938492731\n",
      "반복 횟수 899 : , 에러값 : 0.011302196076267035, 결과값 : 0.988697803923733\n",
      "반복 횟수 999 : , 에러값 : 0.010165031638684097, 결과값 : 0.9898349683613159\n"
     ]
    }
   ],
   "source": [
    "# 편향 추가\n",
    "\n",
    "x = 0\n",
    "y = 1\n",
    "w = tf.random.normal([1], 0,1) \n",
    "b = tf.random.uniform([1], 0,1)\n",
    "\n",
    "a = 0.1\n",
    "for i in range(1000): \n",
    "    output = sigmoid(x * w + 1 * b) \n",
    "    error = y - output\n",
    "    w = w + x * a * error\n",
    "    b = b + 1 * a * error\n",
    "    \n",
    "    if i % 100 == 99:\n",
    "        print('반복 횟수 {0} : , 에러값 : {1}, 결과값 : {2}'.format(i,error, output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-aspect",
   "metadata": {},
   "source": [
    "## AND 연산\n",
    "* AND 연산은 입력이 모두 참 값일 때 참이 되고, 그 밖의 경우에는 모두 거짓이 된다.\n",
    "* 프로그래밍에서는 관습적으로 거짓을 0이라 표시하고 참을 0이 아닌 다른 값으로 표시한다.\n",
    "\n",
    "![AND](https://user-images.githubusercontent.com/28593767/112101737-7e269d00-8bea-11eb-8c87-bf3d24a1c1a7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "capital-conclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 -0.11003026359524606\n",
      "399 -0.06561083806139906\n",
      "599 -0.04662799899970279\n",
      "799 -0.0360600564674673\n",
      "999 -0.029343878767919766\n",
      "1199 -0.0247078635438404\n",
      "1399 -0.02132126880362394\n",
      "1599 -0.018741055609916114\n",
      "1799 -0.016710722647793632\n",
      "1999 -0.015073397967912374\n"
     ]
    }
   ],
   "source": [
    "# AND 연산 \n",
    "# x, y를 넘파이 array로 정의\n",
    "# 리스트는 정수가 아닌 수를 곱할 수 없지만 array는 실수를 곱할 수 있다.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[1,1],[1,0],[0,1],[0,0]])  # 입력값\n",
    "y = np.array([[1],[0],[0],[0]])          # 출력값\n",
    "w = tf.random.normal([2],0,1)            # 초기 가중치\n",
    "b = tf.random.normal([1],0,1)            # 편향\n",
    "b_x = 1                                  # 고정된 편향값\n",
    "\n",
    "# 하이퍼 파라미터(학습율)\n",
    "a = 0.1\n",
    "for i in range(2000):\n",
    "    error_sum = 0\n",
    "    \n",
    "    for j in range(4):\n",
    "        output = sigmoid(np.sum(x[j]*w) + b_x*b) \n",
    "        error = y[j][0] - output\n",
    "        w = w + x[j] * a * error       # 원소에 대한 연산(element-wise)\n",
    "        b = b + b_x * a * error\n",
    "        error_sum += error\n",
    "        \n",
    "    # Print only 200th result\n",
    "    if i % 200 == 199:\n",
    "        print(i, error_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "favorite-flavor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [1 1] Y: [1] Output: 0.9648089445513748\n",
      "X: [1 0] Y: [0] Output: 0.024937239196749072\n",
      "X: [0 1] Y: [0] Output: 0.02501355162346913\n",
      "X: [0 0] Y: [0] Output: 2.3931678496725494e-05\n"
     ]
    }
   ],
   "source": [
    "# 네트워크에 x값을 넣었을 때 실제 출력이 기대 출력인 y값에 얼마나 가까운지 확인\n",
    "for i in range(4):\n",
    "    print('X:', x[i], 'Y:', y[i], 'Output:', sigmoid(np.sum(x[i]*w)+b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-dressing",
   "metadata": {},
   "source": [
    "## OR 연산\n",
    "![OR](https://user-images.githubusercontent.com/28593767/112101739-7f57ca00-8bea-11eb-8034-37e1c7fd82ff.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "other-brain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 -0.055589407683865805\n",
      "399 -0.027496425772412764\n",
      "599 -0.01813171942996268\n",
      "799 -0.013472537244346189\n",
      "999 -0.0106970758600052\n",
      "1199 -0.008859700486486537\n",
      "1399 -0.007555966653526737\n",
      "1599 -0.006583863649986907\n",
      "1799 -0.005831621396811891\n",
      "1999 -0.005231466921091981\n"
     ]
    }
   ],
   "source": [
    "# OR 연산 \n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[1,1],[1,0],[0,1],[0,0]])  # 입력값\n",
    "y = np.array([[1],[1],[1],[0]])          # 출력값  <--- AND연산과의 차이\n",
    "w = tf.random.normal([2],0,1)            # 초기 가중치\n",
    "b = tf.random.normal([1],0,1)            # 편향\n",
    "b_x = 1                                  # 고정된 편향값\n",
    "\n",
    "for i in range(2000):\n",
    "    error_sum = 0\n",
    "    \n",
    "    for j in range(4):\n",
    "        output = sigmoid(np.sum(x[j]*w) + b_x*b) \n",
    "        error = y[j][0] - output\n",
    "        w = w + x[j] * 0.1 * error       # 원소에 대한 연산(element-wise)\n",
    "        b = b + b_x * 0.1 * error\n",
    "        error_sum += error\n",
    "        \n",
    "    # Print only 200th result\n",
    "    if i % 200 == 199:\n",
    "        print(i, error_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "funny-scott",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [1 1] Y: [1] Output: 0.9999970693684695\n",
      "X: [1 0] Y: [1] Output: 0.9896264698278397\n",
      "X: [0 1] Y: [1] Output: 0.9896081851184444\n",
      "X: [0 0] Y: [0] Output: 0.02593388818460478\n"
     ]
    }
   ],
   "source": [
    "# 네트워크에 x값을 넣었을 때 실제 출력이 기대 출력인 y값에 얼마나 가까운지 확인\n",
    "for i in range(4):\n",
    "    print('X:', x[i], 'Y:', y[i], 'Output:', sigmoid(np.sum(x[i]*w)+b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-costs",
   "metadata": {},
   "source": [
    "## XOR 연산\n",
    "![xor](https://user-images.githubusercontent.com/28593767/112101827-a8785a80-8bea-11eb-80fb-af0fedefb382.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "delayed-comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 0.004497410850683559\n",
      "399 0.00018280430645190027\n",
      "599 7.427080467192759e-06\n",
      "799 2.9689667957466526e-07\n",
      "999 3.722842145670313e-09\n",
      "1199 1.8614210173240053e-09\n",
      "1399 1.8614210173240053e-09\n",
      "1599 1.8614210173240053e-09\n",
      "1799 1.8614210173240053e-09\n",
      "1999 1.8614210173240053e-09\n"
     ]
    }
   ],
   "source": [
    "# XOR 연산 \n",
    "# AND, OR 연산과 동일하게 작성\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[1,1],[1,0],[0,1],[0,0]])  # 입력값\n",
    "y = np.array([[0],[1],[1],[0]])          # 출력값\n",
    "w = tf.random.normal([2],0,1)            # 초기 가중치\n",
    "b = tf.random.normal([1],0,1)            # 편향\n",
    "b_x = 1                                  # 고정된 편향값\n",
    "\n",
    "for i in range(2000):\n",
    "    error_sum = 0\n",
    "    for j in range(4):\n",
    "        output = sigmoid(np.sum(x[j]*w) + b_x*b) \n",
    "        error = y[j][0] - output\n",
    "        w = w + x[j] * 0.1 * error       # 원소에 대한 연산(element-wise)\n",
    "        b = b + b_x * 0.1 * error\n",
    "        error_sum += error\n",
    "        \n",
    "    # Print only 200th result\n",
    "    if i % 200 == 199:\n",
    "        print(i, error_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "prime-monaco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [1 1] Y: [0] Output: 0.5128176323940516\n",
      "X: [1 0] Y: [1] Output: 0.5128176314633411\n",
      "X: [0 1] Y: [1] Output: 0.4999999990686774\n",
      "X: [0 0] Y: [0] Output: 0.49999999813735485\n",
      "w: tf.Tensor([5.1281769e-02 3.7252903e-09], shape=(2,), dtype=float32)\n",
      "b: tf.Tensor([-7.450581e-09], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 에러값이 점점 줄어들다 어느 순간 변하지 않는다.\n",
    "# XOR 연산은 신경망으로 풀 수 없다.\n",
    "\n",
    "for i in range(4):\n",
    "    print('X:', x[i], 'Y:', y[i], 'Output:', sigmoid(np.sum(x[i]*w)+b))\n",
    "    \n",
    "print('w:', w)\n",
    "print('b:', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-dependence",
   "metadata": {},
   "source": [
    "### AND 연산과 XOR 연산의 차이\n",
    "* AND 연산의 가중치가 하려는 작업은 XOR 연산에 비해 분명하다.\n",
    "* AND 연산 두 개의 가중치가 비슷하기 때문에 입력 2개는 서로 거의 비슷한 중요도를 지닌다.\n",
    "* 편향값은 큰 음수로 중간 계산값을 음수로 보내려는 경향을 확인할 수 있다.\n",
    "* 두 가중치를 모두 합쳐야 음수 편향을 이겨낼 수 있다.\n",
    "* 반면 XOR 연산는 어떤 일을 하려는지 명확하지 않다. \n",
    "    + 가중치 w1이 w2에 비해 좀 더 큰 값을 가지고 있기는 하지만 중간 계산 값은 0에 가까워지고 시그모이드 함수를 취한 값은 0.5에 가까워질 뿐이다.\n",
    "    \n",
    "![and_xor](https://user-images.githubusercontent.com/28593767/112101741-7ff06080-8bea-11eb-9be0-28bc1d02c535.png)    \n",
    "    \n",
    "> 이것이 바로 첫 번째 인공지능의 겨울을 불러온 것으로 잘 알려진 **XOR 문제(XOR Problem)** 이다. \n",
    "> \n",
    "> 하나의 퍼셉트론으로는 간단한 XOR 연산자도 만들어 낼 수 없다는 것을 동명의 책인 \"퍼셉트론\"에서 마빈 민스키와 시모어 페퍼트가 증명했다.\n",
    ">\n",
    "> 해결책은 바로 **여러 개의 퍼셉트론을 사용하는 것**이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "national-gossip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 세 개의 퍼셉트론과 뉴런을 이용한 XOR 연산\n",
    "\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "\n",
    "x = np.array([[1,1],[1,0],[0,1],[0,0]]) \n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(units=2,activation='sigmoid',input_shape=(2,)), \n",
    "                             tf.keras.layers.Dense(units=1,activation='sigmoid')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.3),loss='mse') \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-phoenix",
   "metadata": {},
   "source": [
    "### tf.keras를 이용한 XOR 네트워크\n",
    "* model : 딥러닝 계산을 간편하게 하기 위한 추상적인 클래스 \n",
    "    + 쉽게 말해 여러 함수와 변수의 묶음이다.\n",
    "* tf.keras.Sequential : 뉴런과 뉴런이 합쳐진 단위인 레이어를 일직선으로 배치한 것\n",
    "* tf.keras.layers.Dense : model에서 사용하는 레이어를 정의하는 명령\n",
    "    + Dense는 가장 기본적인 레이어로서 레이어의 입력과 출력 사이에 있는 모든 뉴런이 서로 연결되는 **완결 연결 계층(Fully Connected Layer)** 레이어이다.\n",
    "* units : 레이어를 구성하는 뉴런의 수를 정의\n",
    "    + 뉴런이 많을수록 일반적으로 레이어의 성능은 좋아지지만 계산량도 많아지고 메모리도 많이 차지하게 된다.\n",
    "* activation : 활성화함수\n",
    "    + 위에서는 sigmoid를 사용했다.\n",
    "* input_shape : 입력의 차원 수가 어떻게 되는지를 정의\n",
    "    + 시퀀셜 모델의 첫 번째 레이어에서만 사용한다.\n",
    "    + 위에서는 각 데이터가 2개의 입력을 받는 1차원 array이므로 1차원 원소의 개수인 2개를 명시해서 (2,)라고 정의했다.\n",
    " \n",
    " \n",
    "* optimizer : 딥러닝의 학습식을 정의하는 부분\n",
    "    + tf.keras에서는 복잡한 수식되신 미리 정의된 최적화 함수를 사용 가능하다.\n",
    "* SGD : 확률적 경사하강법(Stochastic Gradient Descent)의 약자\n",
    "    + 경사하강법은 가중치를 업데이트할 때 미분을 통해 기울기를 구한 다음 기울기가 낮은 쪽으로 업데이트한다는 의미이고 확률적은 확률적으로 일부 샘플을 구해서 조금씩 나눠서 계산하겠다는 의미이다.\n",
    "* loss : error와 비슷한 개념\n",
    "    + mse는 평균제곱오차의 약자로 기대 출력(y_k)에서 실제 출력(output_k)을 뺀 뒤에 제곱한 값을 평균하는 것으로 구한다.\n",
    "* model.summary() : 현재 네트워크 구조를 알아보기 쉽게 출력하는 기능   \n",
    "\n",
    "\n",
    "* Trainable params : 학습 가능한 파라미터\n",
    "* Non-trainable params : 학습 불가능한 파라미터 (다른 신경망을 불러 사용할 때)\n",
    "\n",
    "\n",
    "#### 편향을 포함한 2-레이어 XOR 네트워크 구조\n",
    "![xor2](https://user-images.githubusercontent.com/28593767/112102202-3fddad80-8beb-11eb-9453-b6563dbbecd9.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-seven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples\n",
      "Epoch 1/500\n",
      "4/4 [==============================] - 1s 165ms/sample - loss: 0.2832\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2750\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2731\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.2712\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.2694\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 7ms/sample - loss: 0.2696\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 10ms/sample - loss: 0.2684\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 10ms/sample - loss: 0.2661\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.2674\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2673\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2659\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2673\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2671\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2672\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.2671\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.2657\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2670\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2669\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2669\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2657\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2671\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.2669\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2668\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2667\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2665\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2666\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2665\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 8ms/sample - loss: 0.2653\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 8ms/sample - loss: 0.2668\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 7ms/sample - loss: 0.2667\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2651\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2651\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2663\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2648\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2661\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.2661\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.2648\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2646\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.2660\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2660\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2660\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2660\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.2644\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2656\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2658\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2655\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2643\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 10ms/sample - loss: 0.2653\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.2655\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2639\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 7ms/sample - loss: 0.2654\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.2641\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2655\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2653\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2650\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2650\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2633\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2650\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 8ms/sample - loss: 0.2634\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2631\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2647\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2646\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2645\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2631\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2643\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2643\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2642\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2629\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2640\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2626\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2640\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2637\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2622\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2637\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2634\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2622\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2621\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2634\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2632\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2633\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2612\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2629\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2628\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2613\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2626\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2611\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2614\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2626\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2620\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2603\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2605\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.2618\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2599\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2617\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2603\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2600\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2617\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2614\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2612\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2595\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2595\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2606\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2604\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2586\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2602\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2600\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2585\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2586\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2599\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2580\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2598\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.2594\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2591\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2576\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2585\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2585\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2582\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2565\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2569\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2581\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2563\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2578\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.285 - 0s 3ms/sample - loss: 0.2576\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.2558\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2571\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.2565\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2568\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2565\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2564\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2560\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2559\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2548\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2552\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2553\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2554\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2537\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2537\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2528\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2541\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2525\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2544\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2524\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2533\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2520\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2534\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2532\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2527\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2528\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2511\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2508\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2519\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2517\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2515\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2503\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2506\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2507\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2505\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2501\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2485\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2485\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2492\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2495\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2491\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2474\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2488\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2470\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2482\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2482\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2467\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2475\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2463\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2472\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2465\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2466\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2459\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2455\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2455\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2449\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2430\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2434\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2444\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2431\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2441\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2439\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2419\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2420\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2426\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2422\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2423\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2417\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2414\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2394\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2404\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2391\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2404\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2400\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2396\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2391\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2388\n",
      "Epoch 201/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2371\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2375\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2367\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2375\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2371\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2369\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2367\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2354\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2356\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2346\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2328\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2346\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2323\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2327\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2323\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2334\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2307\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2326\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2320\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2311\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2315\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2296\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2309\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2300\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2301\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2296\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2295\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2288\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2271\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2279\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2264\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2251\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2262\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2260\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2262\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2254\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2246\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2242\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2247\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2236\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2235\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2227\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2222\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2207\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2228\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2220\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2207\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2202\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2194\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2196\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2193\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2195\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2191\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2185\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2181\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2168\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2152\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2151\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2155\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2167\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2141\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2157\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2145\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2146\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2139\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2135\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2131\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2126\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2102\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2104\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2099\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2115\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2096\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2100\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2087\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2093\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2089\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2065\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2083\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2077\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2067\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2071\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2067\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2043\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2053\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2058\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2052\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2031\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2043\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2038\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2033\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2030\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.2013\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2020\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2007\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.2004\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2004\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1981\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1983\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1977\n",
      "Epoch 301/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1995\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1987\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1973\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1961\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1975\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1960\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1948\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1958\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1959\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1950\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1936\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1934\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1938\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1930\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1926\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1916\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1917\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1905\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1909\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1903\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1899\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1894\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1880\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1886\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1871\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1875\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1865\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1865\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1863\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1850\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1850\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1845\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1840\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1836\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1816\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1828\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1819\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1800\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1814\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1803\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1781\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1787\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1779\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1790\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1772\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1755\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1771\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1764\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1740\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1755\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1740\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1729\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1727\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1731\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1708\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1714\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1711\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1707\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1688\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1685\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1687\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1679\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1673\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1666\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1651\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1655\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1634\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1638\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1625\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1630\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1608\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1611\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1611\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1603\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1581\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1574\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1576\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1566\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1567\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1560\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1541\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1544\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1524\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1523\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1516\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1513\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1500\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1498\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1479\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1480\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1461\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1450\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1450\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1451\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1427\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1420\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 7ms/sample - loss: 0.1424\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1408\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1407\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1399\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1383\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1375\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1363\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1366\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1354\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1334\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1328\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1321\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1306\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1309\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1287\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1276\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1275\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1267\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1260\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1245\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1244\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1234\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1217\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1204\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1207\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1184\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1178\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1182\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1158\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1147\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1135\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 7ms/sample - loss: 0.1139\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1123\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1109\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1099\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1100\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1092\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1081\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1072\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1063\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1043\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1043\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1026\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.1019\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.1011\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0999\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0985\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0989\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0969\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0961\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0952\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0943\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0942\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0933\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0917\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0907\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0905\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0897\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0888\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0873\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0872\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0855\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0854\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0842\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0837\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0818\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0814\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0809\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0799\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0797\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0780\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0776\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0763\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0758\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0752\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0744\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0737\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0729\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0726\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0714\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0706\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0705\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 2ms/sample - loss: 0.0697\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0690\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0682\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0675\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0668\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0663\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0651\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0650\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0642\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0633\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0628\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0620\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0618\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0611\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0602\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.0600\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0590\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0584\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0581\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0574\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0567\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0564\n"
     ]
    }
   ],
   "source": [
    "# 네트워크 실제 학습\n",
    "history = model.fit(x, y, epochs=500, batch_size=1)\n",
    "\n",
    "# 학습이 끝난 네트워크 평가\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-alexander",
   "metadata": {},
   "source": [
    "* model.fit() : 에폭(epoch)에 지정된 횟수만큼 학습\n",
    "* epoch : 훈련 데이터를 반복 학습 시키는 횟수 \n",
    "* batch_size : 한번에 학습시키는 데이터의 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-rogers",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
