{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "numerical-volunteer",
   "metadata": {},
   "source": [
    "# Abalone Age Prediction\n",
    "\n",
    "![method](https://user-images.githubusercontent.com/28593767/112245885-1e390080-8c95-11eb-9dee-5f66bb94cbf8.png)\n",
    "\n",
    "회귀 분석을 이용한 전복 나이 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-associate",
   "metadata": {},
   "source": [
    "## Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brown-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exact-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyper parameters\n",
    "RAND_MEAN = 0\n",
    "RAND_STD = 0.0030\n",
    "\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "smaller-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement main function\n",
    "# epoch number, minibatch size, output report, training rate\n",
    "def main_exec(epoch_count=10, mb_size=10, report=1, train_rate=0.8):\n",
    "    load_dataset()   # Load data\n",
    "    init_model()     # Initialize parameters\n",
    "    train_and_test(epoch_count, mb_size, report, train_rate)   # Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "collected-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement loading dataset function\n",
    "def load_dataset():\n",
    "    with open('data_nn/abalone.csv') as csv_file:\n",
    "        csvreader = csv.reader(csv_file)\n",
    "        next(csvreader, None)    # Skip the first row (column info)\n",
    "        rows = []\n",
    "        # Store csv data to empty list, rows\n",
    "        for row in csvreader:\n",
    "            rows.append(row)\n",
    "    # Global variable (전역 변수)\n",
    "    # Input vector size increases from 8 to 10 (One-hot vector)\n",
    "    global data, input_cnt, output_cnt\n",
    "    input_cnt, output_cnt = 10, 1    # Size of independant and dependant variables\n",
    "    data = np.zeros([len(rows), input_cnt+output_cnt])   # Buffer\n",
    "    \n",
    "    # One-hot vector\n",
    "    # I = [1,0,0], M = [0,1,0], F = [0,0,1]\n",
    "    for n, row in enumerate(rows):\n",
    "        if row[0] == 'I': data[n, 0] = 1\n",
    "        if row[0] == 'M': data[n, 1] = 1\n",
    "        if row[0] == 'F': data[n, 2] = 1\n",
    "        data[n, 3:] = row[1:]    # For the rest, store data from enumerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "first-shakespeare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.      1.      0.     ...  0.101   0.15   15.    ]\n",
      " [ 0.      1.      0.     ...  0.0485  0.07    7.    ]\n",
      " [ 0.      0.      1.     ...  0.1415  0.21    9.    ]\n",
      " ...\n",
      " [ 0.      1.      0.     ...  0.2875  0.308   9.    ]\n",
      " [ 0.      0.      1.     ...  0.261   0.296  10.    ]\n",
      " [ 0.      1.      0.     ...  0.3765  0.495  12.    ]]\n"
     ]
    }
   ],
   "source": [
    "# data 출력 형태 확인 (원 핫 벡터 확인)\n",
    "\n",
    "with open('data_nn/abalone.csv') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    next(csvreader, None)    # Skip the first row (column info)\n",
    "    rows = []\n",
    "    for row in csvreader:\n",
    "        rows.append(row)\n",
    "        \n",
    "global data\n",
    "data = np.zeros([len(rows), 11]) \n",
    "\n",
    "for n, row in enumerate(rows):\n",
    "    if row[0] == 'I': data[n, 0] = 1\n",
    "    if row[0] == 'M': data[n, 1] = 1\n",
    "    if row[0] == 'F': data[n, 2] = 1\n",
    "    data[n, 3:] = row[1:]  \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "contemporary-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement parameters initializing function\n",
    "\n",
    "def init_model():\n",
    "    global weight, bias, input_cnt, output_cnt\n",
    "    weight = np.random.normal(RAND_MEAN, RAND_STD, [input_cnt, output_cnt])\n",
    "    bias = np.zeros([output_cnt])\n",
    "    # print(weight)\n",
    "    # print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "internal-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement training and testing function & Ouput training result\n",
    "\n",
    "def train_and_test(epoch_count, mb_size, report, train_rate):\n",
    "    step_count = arrange_data(mb_size, train_rate)  # Return how many steps in each minibatch\n",
    "    test_x, test_y = get_test_data()                # Get x and y value from test data\n",
    "    \n",
    "    # Nested for-loop\n",
    "    for epoch in range(epoch_count):\n",
    "        losses, accs = [], []         # Store loss and accuracy of total minibatch (1 epoch)\n",
    "        for n in range(step_count):\n",
    "            # Return x and y value from train data from minibatch size and step count\n",
    "            train_x, train_y = get_train_data(mb_size, n)\n",
    "            loss, acc = run_train(train_x, train_y)\n",
    "            losses.append(loss)\n",
    "            accs.append(acc)\n",
    "        \n",
    "        if report > 0 and (epoch+1) % report == 0:\n",
    "            acc = run_test(test_x, test_y)\n",
    "            # format 5.3f : 소수점을 포함한 전체 자릿수.소수점 이하 자릿수\n",
    "            print(\"Epoch {} : Train - loss = {:5.3f}. accuracy = {:5.3f} / Test = {:5.3f}\".\\\n",
    "                  format(epoch+1, np.mean(losses), np.mean(accs), acc))\n",
    "            \n",
    "        final_acc = run_test(test_x, test_y)\n",
    "        print(\"\\n 최종 테스트 결과 : final accuracy = {:5.3f}.format(final_acc)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "needed-young",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터의 수(행) : 4177\n",
      "데이터의 70%의 미니배치 스텝 수 : 29\n"
     ]
    }
   ],
   "source": [
    "print(\"총 데이터의 수(행) :\", data.shape[0])\n",
    "mb_size = 100\n",
    "step_count = int(data.shape[0] * 0.7) // mb_size\n",
    "print(\"데이터의 70%의 미니배치 스텝 수 :\", step_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-decimal",
   "metadata": {},
   "source": [
    "## Arranging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "solar-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement arranging data function\n",
    "\n",
    "def arrange_data(mb_size, train_rate):\n",
    "    global data, shuffle_map, test_begin_index\n",
    "    # Randomly shuffle the data\n",
    "    shuffle_map = np.arrange(data.shape[0])\n",
    "    np.random.shuffle(shuffle_map)\n",
    "    # Get minibatch step count\n",
    "    step_count = int(data.shape[0] * train_rate) // mb_size\n",
    "    \n",
    "    # Get training and testing data boundatry index\n",
    "    test_begin_index = step_count * mb_size\n",
    "    \n",
    "    return step_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement dividing train data function\n",
    "def get_train_data(mb_size, nth):\n",
    "    global data, shuffle_map, test_begin_index, output_cnt\n",
    "    if nth == 0 :\n",
    "        np.random.shuffle(shuffle_map[:test_begin_index])\n",
    "    train_data = data[shuffle_map[mb_size * nth : mb_size * (nth+1)]]\n",
    "    \n",
    "    return train_data[:, :-output_cnt], train_data[:, -output_cnt:]\n",
    "\n",
    "# Implement dividing train data function test data function\n",
    "def get_test_data():\n",
    "    global data, shuffle_map, test_begin_index, output_cnt\n",
    "    test_data = data[shuffle_map[test_begin_index:]]\n",
    "    \n",
    "    return test_data[:. :-output_cnt], train_data[:, -output_cnt:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "liquid-bailey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 11)\n",
      "------------------------------------------------------------\n",
      "0 [ 0.     0.     1.     0.49   0.37   0.14   0.585  0.243  0.115  0.195\n",
      " 10.   ]\n",
      "1 [1.     0.     0.     0.375  0.29   0.085  0.2385 0.118  0.045  0.0695\n",
      " 7.    ]\n",
      "2 [ 0.     0.     1.     0.45   0.35   0.135  0.56   0.231  0.137  0.145\n",
      " 13.   ]\n",
      "3 [0.     1.     0.     0.155  0.115  0.025  0.024  0.009  0.005  0.0075\n",
      " 5.    ]\n",
      "4 [0.     0.     1.     0.635  0.49   0.155  1.145  0.4775 0.3035 0.3155\n",
      " 9.    ]\n"
     ]
    }
   ],
   "source": [
    "nth = 0\n",
    "mb_size = 100\n",
    "\n",
    "train_data = data[shuffle_map[mb_size * nth : mb_size * (nth+1)]] \n",
    "print(train_data.shape)\n",
    "\n",
    "print(\"---\"*20)\n",
    "for n, i in enumerate(train_data[0:5]):\n",
    "    print(n,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "narrative-flash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경계 인덱스 생성 :  3300\n",
      "일반적인 순서 \n",
      " [   0    1    2 ... 4174 4175 4176]\n",
      "처음부터 경계선까지의 순서 셔플 \n",
      " [2189 1235 3227 ... 4174 4175 4176]\n",
      "3295번째부터 3305번째까지의 순서 출력 \n",
      " [  79 1664 2044  677 3111 3300 3301 3302 3303 3304]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle data\n",
    "shuffle_map = np.arange(data.shape[0])\n",
    "# Get minibatch step count\n",
    "step_count = int(data.shape[0] * 0.8) // mb_size \n",
    "# Get training data and testing data boundary index\n",
    "test_begin_index = step_count * mb_size\n",
    "# Print boundary index\n",
    "print(\"경계 인덱스 생성 : \", test_begin_index) \n",
    "# Print regular order\n",
    "print(\"일반적인 순서 \\n\", shuffle_map) \n",
    "np.random.shuffle(shuffle_map[:test_begin_index]) \n",
    "# Print shuffled order till boundary index\n",
    "# Print shuffled data from 0 to 3300 and regular data after\n",
    "print(\"처음부터 경계선까지의 순서 셔플 \\n\", shuffle_map) \n",
    "# Print shuffled data from 3295 to 3300 and regular data from 3300 to 3395\n",
    "print(\"3295번째부터 3305번째까지의 순서 출력 \\n\", shuffle_map[3295:3305]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-kidney",
   "metadata": {},
   "source": [
    "## Training data\n",
    "\n",
    "run_train()은 학습을 수행하는 과정이다.\n",
    "\n",
    "1. 순전파 과정을 통해 얻은 예측에 대한 손실 구하기\n",
    "    * forward_neuralnet(), forward_postproc()\n",
    "2. 예측된 값을 바탕으로 정확도 산출하기\n",
    "    * eval_accuracy()\n",
    "3. 손실이 나오기까지 영향을 미친모든 요소에 대한 기울기 구하기\n",
    "    * backprop_postproc(), backprop_neuralnet()\n",
    "    \n",
    "이렇게 구한 결괏값을 학습률과 곱해 기존 파라미터에서 빼주는 학습단계로 진행된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "governing-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(x, y):\n",
    "    pass\n",
    "def run_test(x, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "progressive-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_neuralnet(x):\n",
    "    global weight\n",
    "    output = np.matmul(x, weight) + bias\n",
    "    # Return output and x. x will be used for backpropagation (aux_nn)\n",
    "    return output, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
