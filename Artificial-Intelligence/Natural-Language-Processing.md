# 자연어 처리 Natural Language Processing

## 자연어 처리 NLP
* 인간이 일상에서 사용하는 언어를 자연어라고 한다.
* 컴퓨터 분야에서는 자연어 의미를 분석해 컴퓨터가 처리할 수 있도록 하는 일을 **자연어 처리(Natural Language Processing)** 혹은 줄여서 **NLP**라고 한다.
* 일반적으로 문장을 일정한 의미가 있는 **토큰(Token)** 이라는 가장 작은 단어들로 나눈 뒤 나눠진 단어들을 이용해 의미를 분석한다.
* 토큰의 단위는 **토크나이징(Tokenizing)** 방법에 따라 달라질 수 있지만 일반적으로 *일정한 의미가 있는 가장 작은 정보 단위로 결정*된다.
* *토크나이징은 문장 형태의 데이터를 처리하기 위해 제일 처음 수행해야 하는 기본적인 작업이며 주로 텍스트 전처리 과정에서 사용*된다.

![nlp](https://user-images.githubusercontent.com/28593767/115187514-6b868180-a11e-11eb-8533-d0914bcb1914.png)

### KoNLPy
* [**KoNLPy**](https://konlpy-ko.readthedocs.io/ko/v0.4.3/) 는 한국어 토크나이징을 지원하는 파이썬 라이브러리로 한국어 자연어 처리에 많이 사용된다.
* 한국어 문장을 분석하려면 토크나이징 작업을 제일 먼저 수행해야 하는데, 이때 토큰 단위를 어떻게 정의하느냐에 따라 자연어 처리 성능에 영향을 미친다.
    + 일정한 의미가 있는 가장 작은 말의 단위, 즉 의미가 더 이상 쪼개지지 않는 **형태소(Morpheme)** 를 토큰 단위로 사용한다.
* 영어의 경우 단어의 변화가 크지 않고, 띄어쓰기로 단어를 구분하기 때문에 공백을 기준으로 토크나이징을 수행해도 큰 문제 없지만 *한국어는 명사와 조사를 띄어 쓰지 않고, 용언에 따라 여러 가지 어미가 붙기 때문에 띄어쓰기만으로는 토크나이징할 수 없다*.
* 따라서 형태소 분석기를 이용하여 문장에서 형태소를 추출하면서 형태소의 뜻과 문맥을 고려해 품사 태깅을 해줘야 한다.

### Kkma
* [**Kkma**](http://kkma.snu.ac.kr/documents/?doc=postag) 는 서울대학교 IDS(Intelligent Data Systems) 연구실에서 자연어 처리를 위해 개발한 한국형 형태소 분석기로 *꼬꼬마*라고 발음한다.
* Kkma는 다음 4가지 함수를 제공한다.
<img width="1292" alt="kkma" src="https://user-images.githubusercontent.com/28593767/115185952-cf5b7b00-a11b-11eb-8900-6b10475a3618.png">

### Komoran 
* [**Komoran(Korean Morphological ANalyzer)**](https://www.shineware.co.kr/products/komoran/#demo?utm_source=komoran-kr&utm_medium=Referral&utm_campaign=github-demo) 은 Shinware에서 개발한 자바 기반 한국어 형태소 분석기로 *코모란*이라고 발음한다.
* Komoran은 다음 3가지 함수를 제공한다.
![komoran](https://user-images.githubusercontent.com/28593767/115186644-0c743d00-a11d-11eb-9d0e-9e10321a5402.png)

### Okt
* [**Okt(Opensource Korean Text Processor)**](https://openkoreantext.org/) 는 트위터에서 개발한 Twitter 한국어 처리기에서 파생된 오픈소스 한국어 처리기이다.
* Okt의 경우 앞서 소개한 형태소 분석기들보다 분석되는 품사 정보는 작지만 분석 속도는 제일 빠르고 또한 normalize() 함수를 지원해 오타가 섞인 문장을 정규화해서 처리하는데 효과적이지만 성능이 뛰어나지는 않다.
* Okt는 다음 5가지 함수를 제공한다.
![okt](https://user-images.githubusercontent.com/28593767/115187507-69bcbe00-a11e-11eb-9740-bb14fa6aa3ec.png)

### 한국어 토크나이징
* 영어의 경우 단순히 토큰 정보만 필요하다면 띄어쓰기만 하더라도 훌륭한 결과를 보여준다. 
* 하지만 *한국어는 명사와 조사를 띄어쓰지 않고, 용언에 따라 여러 가지 어미가 붙기 때문에 띄어쓰기만으로는 토크나이징을 할 수 없다*. 
* 따라서 KoNLPy의 형태소 분석기를 이용해 형태소 단위의 토큰과 품사 정보까지 추출하고 추출된 정보에서 필요 없는 정보를 제거하는 **전처리(Preprocessing)** 과정이 추가되어야 한다.

![konlpy](https://user-images.githubusercontent.com/28593767/115188134-71c92d80-a11f-11eb-9dbc-e3db0889475e.png)


## 임베딩 Embedding
* 컴퓨터는 수치 연산만 가능하기 때문에 자연어를 숫자나 벡터 형태로 변환해야 한다. 
* 임베딩은 **단어나 문장을 수치화해 벡터 공간으로 표현하는 과정**을 의미한다. 
* 임베딩은 말뭉치의 의미에 따라 벡터화하기 때문에 문법적인 정보가 포함되어 있다. 
* 임베딩 기법에는 문장 전체를 벡터로 표현하는 문장 임베딩과 개별 단어를 벡터로 표현하는 단어 임베딩이 있다.
    + 문장 임베딩의 경우 *전체 문장의 흐름을 파악해 벡터로 변환하기 때문에 문맥적 의미를 지니는 장점*이 있다.
    + 하지만 *임베딩하기 위해 많은 문장 데이터가 필요하며 학습하는데 비용*이 많이 들어간다.
    + 반면 단어 임베딩은 문장 임베딩에 비해 학습 방법이 간단해 *실무에서 많이 사용*된다.
    + 하지만 단어 임베딩은 *동음이의어에 대한 구분을 하지 않기 때문에 의미가 다르더라도 단어의 형태가 같다면 동일한 벡터값으로 표현되는 단점*이 있다.

### 단어 임베딩 Word Embedding
* 단어 임베딩은 말뭉치에서 각각의 단어를 벡터로 변환하는 기법으로 의미와 문법적 정보를 지니고 있으며, 단어를 표현하는 방법에 따라 다양한 모델이 존재한다.

<img width="484" alt="onehot" src="https://user-images.githubusercontent.com/28593767/115192638-09317f00-a126-11eb-8c21-4569f91c4aa4.png">

* **원-핫 인코딩(One-Hot Encoding)** 은 단어를 숫자 벡터로 변환하는 가장 기본적인 방법으로 단 하나의 값만 1이고 나머지 요솟값은 0인 인코딩을 의미한다. 
* 원-핫 인코딩으로 나온 결과를 **원-핫 벡터(One-Hot Vector)** 라 하며, 전체 요소 중 단 하나의 값만 1이기 때문에 **희소 벡터(Sparse Vector)** 라고 한다.
* 원-핫 인코딩을 하기 위해서는 단어 집합이라 불리는 사전을 먼저 만들어야 한다. 
    + 사전이란 말뭉치에서 나오는 서로 다른 모든 단어의 집합을 의미한다. 
    + 말뭉치에 존재하는 모든 단어의 수가 원-핫 벡터의 차원을 결정한다.
    + 사전 내 단어 순서대로 고유한 인덱스 번호를 부여해 단어의 인덱스 번호가 원-핫 인코딩에서 1의 값을 가지는 요소의 위치가 부여된다.
* 이처럼 단어가 희소 벡터로 표현되는 방식을 **희소 표현(Sparse Representation)** 이라고 한다.
    + 희소 표현은 각각의 차원이 독립적인 정보를 지니고 있어 사람이 이해하기에 직관적인 장점이 있지만 *단어 사전의 크기가 커질수록 메모리 낭비와 계산 복잡도가 커지는 단점*이 있다.
    + 또한 *기본 토큰이 되는 단어의 의미와 주변 단어 간의 관계를 단어 임베딩에 표현할 수 없다는 단점*도 있다.

<img width="394" alt="distri" src="https://user-images.githubusercontent.com/28593767/115192633-0767bb80-a126-11eb-9314-086c7f80e740.png">

* **분산 표현(Distributed Representation)** 은 한 단어의 정보가 특정 차원에 표현되지 않고 여러 차원에 분산되어 표현되어 붙여진 이름이다.
    + 원하는 차원에 데이터를 최대한 밀집시킬 수 있어 **밀집 표현(Dense Representation)** 이라 부르기도 하며 밀집 표현으로 만들어 진 벡터를 **밀집 벡터(Dense Vector)** 라고 한다.
* 희소 표현과 달리 **각 단어 간의 유사성을 잘 표현하면서도 벡터 공간을 절약할 수 있는 방법**으로 하나의 차원에 다양한 정보를 가지고 있다.
* 분산 표현의 첫번째 장점은 **임베딩 벡터의 차원을 데이터 손실을 최소화하면서 압축할 수 있다**는 점이다.
    + 희소 표현 방식은 단어를 표현하는 데 너무 많은 차원이 필요하고 단어 사전이 커질수록 비효율적이고 희소 벡터이기 때문에 대부분의 값이 0이 된다.
    + 입력 데이터의 차원이 너무 높아지면 신경망 모델의 학습이 어려워지는 **차원의 저주(Curse of Dimentionality)** 문제가 발생한다.
* 또한 분산 표현의 두 번째 장점은 **임베딩 벡터에는 단어의 의미, 주변 단어간의 관계 등 많은 정보가 표현되어 있어 일반화 능력이 뛰어나다**는 점이다.
    + 예를 들어 남자와 남성이라는 단어가 있을 때 희소 표현 방식에는 그저 단 하나의 요솟값에 불과하다.
    + 즉, 남자와 남성의 관계가 전혀 표현되어 있지 않는다.
    + 하지만 분산 표현에서는 *벡터 공간 상에서 유사한 의미를 갖는 단어들은 비슷한 위치에 분포*되어 있기 때문에 남자와 남성의 단어 위치는 매우 가깝다.








