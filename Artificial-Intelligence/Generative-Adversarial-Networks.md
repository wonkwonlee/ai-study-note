# GAN Generative Adversarial Networks

## Turing Test
> *기계는 사고할 수 있을까?* 엘런 튜링은 그의 논문 "**computing machinery and intelligence**" 에서 오늘날 튜링 테스트라고 알려진 이미테이션 게임이라는 실험을 제안했다. 

* 머신러닝 알고리즘은 이미 존재하는 데이터에서 패턴을 인식하고 그 통찰을 사용하여 분류나 회귀와 같은 작업을 처리 하는 데 뛰어나지만 컴퓨터가 새로운 데이터를 생성하는 것은 쉽지 않다.
* 2014년 몬트리올 대학교의 이언 굿펠로(Ian Goodfellow)가 GAN을 발명한 이후 상황이 바뀌게 되었다.
* GAN은 신경망 하나가 아닌 *두 개의 구분된 신경망을 이용해 실제와 유사한 데이터를 생성*한다.
* 이를 통해 레이블된 훈련 데이터를 대량으로 준비하지 않은 상태로 진짜 같은 품질의 가짜 이미지를 생성하거나, 낙서를 사진 같은 이미지로 만들거나, 말 영상을 달리는 얼룩말 영상으로 만들 수 있게 되었다.


## GAN의 정의
<img width="1005" alt="gan" src="https://user-images.githubusercontent.com/28593767/116950074-f3dc5900-acbe-11eb-986b-dddb5bc6b4c5.png">

* GAN은 **생성적 적대 신경망(Generative Adversarial Networks)** 의 약자로 동시에 두 개의 모델을 훈련하는 머신러닝의 한 종류이다.
    + **생성자(Generator)** 는 가짜 데이터를 생성하도록 훈련되고 **판별자(Discriminator)** 는 실제 샘플과 가짜 샘플을 구분하도록 훈련한다.
* **생성적(Generative)** 라는 용어는 *새로운 데이터를 생성한다는 이 모델의 목적*을 나타낸다.
    + GAN이 생성하기 위해 학습할 데이터는 훈련 데이터셋에 따라 결정된다. 
    + 예를 들어 GAN을 이용해 레오나르도 다빈치의 작품처럼 보이는 이미지를 만들고 싶다면 다빈치의 작품을 훈련 데이터셋으로 사용하면 된다.
* **적대적(Adversarial)** 이라는 용어는 *GAN의 뼈대를 이루는 두 모델인 생성자와 판별자 사이의 게임 같은 경쟁 구도*를 나타낸다.
    + *생성자의 목표는 훈련 데이터셋에 있는 실제 데이터와 구분이 안될 정도로 유사한 샘플을 만드는 것이고 판별자의 목표는 생성자가 만든 가짜 데이터를 훈련 데이터셋에 있는 실제 데이터와 구별하는 것*이다.
    + 예를 들어 생성자는 다빈치의 그림처럼 보이는 그림을 생성하고 판별자는 다빈치의 것으로 보이는 그림이 진짜인지 조사한다.
* *생성자와 판별자는 서로를 이기려는 경쟁을 지속*하고 생성자가 더 그럴듯한 데이터를 생성할수록 판별자 역시 가짜와 진짜를 구별하는 일에 탁월해져야 한다.

<img width="1172" alt="gan2" src="https://user-images.githubusercontent.com/28593767/116950078-f8a10d00-acbe-11eb-8b1a-327dc519e322.png">

* 생성자의 목표는 훈련 데이터와 구별이 안 될 정도로 훈련 데이터셋의 특징이 잘 나타난 샘플을 생성하는 것이다.
    + 객체 탐지 모델과는 반대로 패턴을 인식하는 대신 이미지를 직접 처음부터 만들도록 학습한다.
    + 생성자는 판별자의 분류 결과에서 피드백을 받아 학습을 계속한다.
* 판별자의 목표는 특정 샘플이 진짜(훈련 데이터)인지 가짜(생성자가 생성한 데이터)인지 구별하는 것이다.
    + 판별자가 가짜를 진짜로 분류할 때마다 생성자는 자신이 임무를 잘 수행하고 있다는 것을 피드백 받고 생성자가 만든 이미지가 가짜라는 걸 판별자가 포착할 때마다 생성자는 더 그럴듯한 결과물을 생성해야 한다는 피드백을 받는다.


### GAN의 구조
<img width="1005" alt="gan3" src="https://user-images.githubusercontent.com/28593767/116950079-f939a380-acbe-11eb-8390-48c160b4fbd2.png">

1. 훈련 데이터셋
    + 생성자가 거의 완벽한 수준으로 모방하기 위해 학습하는 진짜 샘플 데이터셋이다.
    + 데이터셋은 *판별자 신경망의 입력(x)* 으로 제공된다.
2. 랜덤한 잡음 벡터
    + 랜덤한 숫자 벡터로 생성자가 *가짜 샘플 합성의 시작점*으로 사용한다.
    + *생성자 신경망의 입력(z)* 으로 제공된다.
3. 생성자 신경망
    + 생성자는 *랜덤한 숫자 벡터(z)를 입력으로 받아서 가짜 샘플(x')을 출력*한다.
    + 생성자의 목표는 훈련 데이터셋의 진짜 샘플과 구별이 안 되는 가짜 샘플을 생성하는 것이다.
4. 판별자 신경망
    + 판별자는 *훈련 데이터셋의 진짜 샘플(x)과 생성자가 만든 가짜 샘플(x')을 입력*으로 받는다. 
    + 판별자는 각 *샘플이 진짜일 확률을 계산*해 출력한다.
5. 반복 훈련
    + 판별자의 예측이 얼마나 정확한지 평가하여 역전파로 판별자와 생성자 신경망을 반복해서 훈련한다.
    + 판별자의 가중치와 편향은 *분류 정확도를 최대화 하도록 업데이트*된다. 
        - *x를 진짜로 판단하고 x'을 가짜로 판단하도록* 올바른 예측의 확률을 최대화 한다.
    + 생성자의 가중치와 편향은 *판별자가 x'을 진짜로 잘못 분류할 확률을 최대화 하도록 업데이트*된다.


### GAN 훈련 알고리즘
매 훈련 반복에서 다음 과정을 반복한다.

1. **판별자 훈련하기**
    + <img width="630" alt="gen" src="https://user-images.githubusercontent.com/28593767/116950243-63524880-acbf-11eb-9176-06c07fbbbc3d.png">
    + 훈련 데이터셋에서 랜덤하게 진짜 샘플 x를 선택
    + 새로운 랜덤한 잡음 벡터 z를 얻어서 생성자 네트워크를 이용해 가짜 샘플 x'을 합성
    + 판별자 신경망을 이용해 x와 x'을 분류
    + *분류 오차를 계산하고 전체 오차를 역전파해서 판별자의 훈련 가능한 파라미터를 업데이트하고 분류 오차를 최소화*

2. **생성자 훈련하기**
    + <img width="630" alt="dis" src="https://user-images.githubusercontent.com/28593767/116950249-65b4a280-acbf-11eb-92e3-91a2c4a64b2a.png">
    + 생성자 신경망을 사용해 새로운 랜덤한 잡음 벡터 z에서 가짜 샘플 x'을 합성
    + 판별자 신경망을 이용해 x'을 분류
    + *분류 오차를 계산하고 역전파해서 생성자의 훈련 가능한 파라미터를 업데이트하고 판별자의 오차를 최대화*

3. **균형에 도달하기**
    + <img width="983" alt="eq" src="https://user-images.githubusercontent.com/28593767/116950252-664d3900-acbf-11eb-9058-47b323f5dedd.png">

