# 분류 Classification

## 이진 판단 문제
* 이진 판단 문제란 예, 아니오 혹은 0, 1 같은 두 가지 값에 대해서 하나로 답하는 문제이다.
* 하지만 이진 판단 문제를 신경망으로 해결하는 것은 까다로운 부분이 존재한다.
  + 가중치와 편향을 이용하는 퍼셉트론의 선형 연산을 살펴보면 하나의 값 만을 출력한다.
  + 즉 두 가지 값으로 결과를 제한할 수 없다.
* 방법은 *선형 연산에서는 범위에 제한이 없는 실숫값을 계산하되, 이를 확률값의 성질에 맞게 즉 0~1 사이의 값을 갖도록 변환*해주는 비선형 활성화 함수, **시그모이드(sigmoid) 함수**를 사용하는 것이다.

![cross](https://user-images.githubusercontent.com/28593767/112778597-d85aae80-907f-11eb-8d5a-5e752744edc5.png)

* *신경망의 예측값에 따른 확률 분포와 실제 결괏값에 따른 확률 분포 사이의 각 확률 분포가 얼마나 다른지를 숫자 하나로 표현*해주는 **교차 엔트로피(Cross Entropy)** 라는 개념으로 풀 수 있다.


## 시그모이드 함수 Sigmoid Function
![sig](https://user-images.githubusercontent.com/28593767/112778601-da247200-907f-11eb-8f64-2dfaab391360.png)

* 시그모이드 함수는 **범위에 제한이 없는 임의의 실숫값을 입력으로 받아 이 값을 확률값의 범위에 해당하는 0과 1 사이의 값으로 다시 연산을 수행**한다.
    + 즉, 선형 연산 결과가 아무리 크다 해도 입력으로 받아 처리할 수 있다.
* 시그모이드 함수는 **입력값(x)** 을 답이 참일 **가능성(odds)** 에 대해서 **로짓(logit)** 으로 표시한 값이라고 간주한다.
    + 로짓이란 실제 표현하려는 값(odds)을 로그값으로 표현한 것으로 시그모이드 함수는 이 로짓값을 확률값으로 변환해주는 함수이다.
* 로짓값으로 표시를 하게 되면 *넓은 범위의 값을 간단하게 표현*할 수 있고 값의 변화를 *변화량보다 변화 비율관점에서 더 민감하게 포착*할 수 있다.

### 시그모이드 함수의 일반화 Generalization of Sigmoid Function
* 참일 가능성과 거짓일 가능성의 로짓값이 각각 x와 0이므로 거짓인 경우의 실제 확률은 *P_F = α* 이고 참인 경우의 실제 확률은 *P_T = αe^x* 가 된다.

<img width="495" alt="sig_cal" src="https://user-images.githubusercontent.com/28593767/112779559-f6291300-9081-11eb-9c9e-2848441989c5.png">


## 정보 엔트로피 Entropy
* 엔트로피 개념에서 힌트를 얻어 확률 분포의 무질서도나 불확실성 혹은 정보 표현의 부담 정도를 나타내는 정보로 **정보 엔트로피 혹은 섀넌 엔트로피(Shannon Entropy)** 라고 한다.
* 정보 이론은 *신호에 존재하는 정보의 양을 측정하는 이론*으로 정보의 양은 간단히 말해 놀람의 정도라고 할 수 있다.
* 예를 들어 전구가 표현할 수 있는 단위 정보수는 2개이니 전구가 1개면 표현 범위는 2, 2개면 4개, 3개면 8개라 할 수 있다.

<img width="1159" alt="info" src="https://user-images.githubusercontent.com/28593767/112780934-d515f180-9084-11eb-8a3a-d0c816f60feb.png">

* 이러한 정보량의 개념은 각 경우에 대한 확률이 균일하지 않은 확률분포에도 확장하여 적용할 수 있다.



