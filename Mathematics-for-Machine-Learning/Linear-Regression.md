# 선형 회귀 Linear Regression
> 지금까지 인공지능에 필요한 수학의 기초를 배웠고 이제부터는 실제로 사용되는 수학의 응용을 배울 차례이다.
>
> 선형회귀 모델은 인공지능 분야에서 가장 단순하면서도 이해하기 쉬운 모델로 직선이나 평면 상에서의 수치 예측 모델을 의미한다.
>
> 통계학에서는 단순 회귀 분석이나 다중 회귀 분석이라고 쓰인다.

## 선형 회귀 Linear Regression
* 선형 회귀는 간단하게 말해서 직선 상의(선형) 수치 예측(회귀) 이라고 할 수 있다.
* 주의할 점은 모델을 만들 때 어느 한 쪽으로 치우친 데이터를 사용하게 되면 제대로 된 관계식을 얻을 수가 없다는 점이다.
* 관계식을 세울 때는 **편향(bias)이 적은 데이터**를 수집하는 것이 중요하다.
* 예를 들어 회귀 모델로 주택 가격을 추정해본다고 하면 주택 가격을 목적 변수 또는 종속 변수라고 하고 추정하는 데 필요한 정보를 설명 변수 또는 독립 변수라고 한다.
* 변수는 크게 네 종류의 척도로 구분된다.
    + ![var](https://user-images.githubusercontent.com/28593767/111720795-f9621900-88a1-11eb-827a-d3203db9d33b.png)


## 선형 회귀 모델 Linear Regression Model
![lg_eq](https://user-images.githubusercontent.com/28593767/111720793-f830ec00-88a1-11eb-9f90-636d4b8528a5.png)

![lg_mat](https://user-images.githubusercontent.com/28593767/111720797-f9faaf80-88a1-11eb-90cc-ec1642e482b2.png)

* 회귀 모델이란 하나의 종속변수를 하나 이상의 독립변수로 기술한 관계식을 의미한다. 
* *w0, w1,... ,wl* 을 계수(weight)라 하고 *x1,x2,... ,xl*을 **독립변수**라고 할 때, **종속변수** *y*에 대한 선형회귀 모델식이다.
* 인공지능 알고리즘이 하는 일은 이 모델식에서 적절한 가중치 *wk*가 무엇인지 찾아서 결정하는 것이다. 
* **인공지능에서는 모델식에 가장 잘 들어맞는 가중치를 찾는 것이 중요하다**.


## 최소제곱법 Least Squared Method
* 최소제곱법에서는 데이터 세트와 같은 수치 데이터들을 **특정 함수를 사용하여 근사적으로 표현**할 수 있다고 가정한다.
* 이러한 함수가 수치 데이터를 잘 표현하기 위해서는 수치 데이터값과 함수의 결괏값 사이에 오차가 최소가 되어야 한다.
* 이 때 오차를 제곱하여 모두 더한 값이 최소가 되는 가중치를 찾아 최종적으로 오차가 가장 작게 나오는 가중치를 모델식의 계수로 사용한다.

![lsm](https://user-images.githubusercontent.com/28593767/111720791-f7985580-88a1-11eb-83c2-b7a2ae1b28ce.png)

![lsm_eq](https://user-images.githubusercontent.com/28593767/111720789-f6672880-88a1-11eb-8471-b42b3b86e022.png)

* 실제 데이터 값과 함수의 결과값 사이의 거리를 모두 더한 값이 최소가 되도록 만들면 된다.
* 모델식에서 거리를 구하기 위해 절댓값을 사용했는데, 절대값이 포함된 수식은 미분할 때 번거롭기에 절댓값을 쓰는 대신에 거리의 제곱으로 바꿔서 최솟값을 구한다.
    + 부과적으로 제곱을 하면 **오차가 큰 수와 오차가 작은 수의 제곱의 차이**가 커지기 때문에 오차를 구분하기가 더 쉬워진다.
* D가 최솟값을 가지려면 *w0와 w1*을 편미분한 값이 0 되어야 한다.
* 이렇게 모델식의 결과와 실제 데이터의 오차가 최소가 되게 만들면서 모델식의 가중치(계수)를 찾는 과정이 최소제곱법이다.


## 모델식의 평가 Evaluation of Model
* 홀드아웃 교차 검증법 Holdout Cross Validation : **하나의 데이터 세트를 학습용 데이터와 테스트용 데이터로** 나눈 다음, 학습 데이터로 학습된 모델을 테스트 데이터로 검증하는 방법이다. 이러한 조정 과정을 **튜닝**이라고 한다.
* k-분할 교차 검증법 k-fold Cross Validation : **데이터 세트를 k개로 분할한 다음, k번에 걸쳐** 학습 데이터와 테스트 데이터의 조합을 바꿔쓰는 방법이다. 

### 평균 제곱 오차 Mean Squared Error
![mse](https://user-images.githubusercontent.com/28593767/111720798-fa934600-88a1-11eb-9fed-3018f834768e.png)

* 학습을 수행하며 모델의 성능을 평가할 수 있는 지표의 하나이다.
* MSE는 잔차의 제곱을 모두 더한 다음 평균을 구한 것이다.
* 따라서 MSE가 작을수록 모델이 더 잘 들어맞는다는 것을 의미한다.

### 통계 vs 머신러닝
* 통계와 머신러닝은 둘 다 데이터를 다루는 학문이고 분석하는 방법도 비슷하다.
    + 예를 들어, 선형 회귀는 통계 분야에서 *다중회귀분석*이나 *단순회귀분석* 이라고 불리며 분석하는 내용도 비슷하고 상당 부분의 내용이 겹치기도 한다.
* 다만, 통계와 머신러닝은 그 *학문이 지향하는 목적* 면에서 큰 차이를 보이는데, **통계는 기존 데이터에 대한 설명**에 무게 중심이 있고 **머신러닝은 기존 데이터를 통한 예측**에 무게 중심이 쏠려 있습니다.
* 따라서 통계에서는 **검증(Validation)** 에 더 충실해야 하고 머신러닝에서는 **예측(Prediction)** 이 더 중요하다.

